{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "85127ef3-2b69-4428-b509-a8a2d967af4a",
   "metadata": {},
   "source": [
    "# PySpark: Connect\n",
    "\n",
    "Spark Connect introduced a decoupled client-server architecture for Spark that allows remote connectivity to Spark clusters using the DataFrame API.\r\n",
    "\r\n",
    "This notebook walks through a simple step-by-step example of how to use Spark Connect to build any type of application that needs to leverage the power of Spark when working with data.\r\n",
    "\r\n",
    "Spark Connect includes both client and server components and we will show you how to set up and use both."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1617a6e-19a1-4d04-be5b-5c5d8209e9ab",
   "metadata": {},
   "source": [
    "## Importing libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f314c65b-1699-45e0-9682-8b239233aa81",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from datetime import datetime, date\n",
    "from pyspark.sql import Row"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bdabc69-6379-4a48-abd0-c64c42a622d6",
   "metadata": {},
   "source": [
    "## Connect to Spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f664a246-6587-4b09-976f-feeb1b0e950f",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder.master(\"local[*]\").getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff432b5c-2ab0-4465-8739-57cc674935ad",
   "metadata": {},
   "source": [
    "## Create DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a862f73f-3a0f-4a13-9e0a-285073b0de3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+---+-------+----------+-------------------+\n",
      "|  a|  b|      c|         d|                  e|\n",
      "+---+---+-------+----------+-------------------+\n",
      "|  1|2.0|string1|2000-01-01|2000-01-01 12:00:00|\n",
      "|  2|3.0|string2|2000-02-01|2000-01-02 12:00:00|\n",
      "|  4|5.0|string3|2000-03-01|2000-01-03 12:00:00|\n",
      "+---+---+-------+----------+-------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = spark.createDataFrame([\n",
    "    Row(a=1, b=2., c='string1', d=date(2000, 1, 1), e=datetime(2000, 1, 1, 12, 0)),\n",
    "    Row(a=2, b=3., c='string2', d=date(2000, 2, 1), e=datetime(2000, 1, 2, 12, 0)),\n",
    "    Row(a=4, b=5., c='string3', d=date(2000, 3, 1), e=datetime(2000, 1, 3, 12, 0))\n",
    "])\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0865e00d-b690-4022-a316-1e8992101bd2",
   "metadata": {},
   "source": [
    "## Close session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "071c660d-d161-4faa-8506-55eba88e7aed",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf5a7923-9cdb-4c3d-8e79-726b31116e0f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
