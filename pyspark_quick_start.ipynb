{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0196267d-32f4-494f-88bd-ed0528c37f21",
   "metadata": {},
   "source": [
    "# PySpark Quickstart: DataFrame\n",
    "\n",
    "## Importing libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "292e3098-dc5c-4512-ae7f-a4b77a48752a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "from datetime import datetime, date\n",
    "from collections.abc import Iterator\n",
    "\n",
    "from environment import print\n",
    "\n",
    "from pyspark.sql import SparkSession, Row, Column, types\n",
    "from pyspark.sql.functions import upper, pandas_udf, rand, col, expr"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "085ee634-5463-4a7c-a1ec-873018ce9e1d",
   "metadata": {},
   "source": [
    "## Checking environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d03eda18-3c3e-4c43-8597-4de08c40c76e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.11.9 | packaged by Anaconda, Inc. | (main, Apr 19 2024, 16:40:41) [MSC v.1916 64 bit (AMD64)]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Check python version\n",
    "import sys\n",
    "print(sys.version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5c1591b4-09fc-434d-9bf4-1de4f88e4baa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python 3.11.9\n"
     ]
    }
   ],
   "source": [
    "!python -V"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "56476678-30a4-4b78-b57b-49680deee0b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPARK_HOME = C:\\Spark\\spark-3.5.1-bin-hadoop3\n",
      "JAVA_HOME = C:\\Program Files\\Java\\latest\\jre-1.8\n",
      "HADOOP_HOME = C:\\Spark\\hadoop-3.3.6\n",
      "hadoop.home.dir = C:\\Spark\\hadoop-3.3.6\n",
      "PYSPARK_PYTHON = C:\\ProgramData\\anaconda3\\envs\\ml\\python.exe\n",
      "PYSPARK_DRIVER_PYTHON = C:\\ProgramData\\anaconda3\\envs\\ml\\python.exe\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Check environment variables\n",
    "import os\n",
    "print(\n",
    "    f\"SPARK_HOME = {os.environ['SPARK_HOME']}\",\n",
    "    f\"JAVA_HOME = {os.environ['JAVA_HOME']}\",\n",
    "    f\"HADOOP_HOME = {os.environ['HADOOP_HOME']}\",\n",
    "    f\"hadoop.home.dir = {os.environ['hadoop.home.dir']}\",\n",
    "    f\"PYSPARK_PYTHON = {os.environ['PYSPARK_PYTHON']}\",\n",
    "    f\"PYSPARK_DRIVER_PYTHON = {os.environ['PYSPARK_DRIVER_PYTHON']}\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74399a1e-a4dd-4a74-8e7f-bf2230abe952",
   "metadata": {},
   "source": [
    "## Spark session function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ad1adfd7-d6a1-42eb-81ec-96a48be855dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Util functions\n",
    "def create_spark_session():\n",
    "    # spark = SparkSession.builder.master('local').appName('ml').getOrCreate()\n",
    "    spark = SparkSession.builder.getOrCreate()\n",
    "\n",
    "    # Setting the log level\n",
    "    spark.sparkContext.setLogLevel(\"WARN\")\n",
    "\n",
    "    # Printing the environment\n",
    "    print(f'Spark version: {spark} - {spark.version}')\n",
    "\n",
    "    # Print the tables in the catalog\n",
    "    print('Available tables:', spark.catalog.listTables())\n",
    "    return spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a2cd50ae-de4f-4f81-9de0-08c652c2d5fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spark version: <pyspark.sql.session.SparkSession object at 0x00000207E82922D0> - 3.5.1\n",
      "\n",
      "Available tables:\n",
      "[]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark = create_spark_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c6af9e57-8acd-4ac2-8d4e-768b77bb68ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Reading table:\n",
      "+----+--------+\n",
      "| age|    name|\n",
      "+----+--------+\n",
      "|NULL|Prashant|\n",
      "|  30|   Abdul|\n",
      "|  19|  Justin|\n",
      "|  43|    Andy|\n",
      "+----+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Reading data\n",
    "print('\\nReading table:', end='\\n')\n",
    "spark.read.json('data-sources/people.json').show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40bda717-235b-4e50-a3df-6c7db60540b6",
   "metadata": {},
   "source": [
    "## DataFrame Creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "28783af6-7333-4d21-89fb-6777cf2e3322",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating a simple spark dataframe:\n",
      "DataFrame[a: bigint, b: double, c: string, d: date, e: timestamp]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Create a PySpark DataFrame from a list of rows\n",
    "df = spark.createDataFrame([\n",
    "    Row(a=1, b=2., c='string1', d=date(2000, 1, 1), e=datetime(2000, 1, 1, 12, 0)),  # noqa\n",
    "    Row(a=2, b=3., c='string2', d=date(2000, 2, 1), e=datetime(2000, 1, 2, 12, 0)),  # noqa\n",
    "    Row(a=4, b=5., c='string3', d=date(2000, 3, 1), e=datetime(2000, 1, 3, 12, 0))   # noqa\n",
    "])\n",
    "print('Creating a simple spark dataframe:', df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1a584abd-d69e-42ad-a2b3-ecd022e708f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating a simple spark dataframe:\n",
      "DataFrame[a: bigint, b: double, c: string, d: date, e: timestamp]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Create a PySpark DataFrame from a list of rows\n",
    "df = spark.createDataFrame([\n",
    "    Row(a=1, b=2., c='string1', d=date(2000, 1, 1), e=datetime(2000, 1, 1, 12, 0)),  # noqa\n",
    "    Row(a=2, b=3., c='string2', d=date(2000, 2, 1), e=datetime(2000, 1, 2, 12, 0)),  # noqa\n",
    "    Row(a=4, b=5., c='string3', d=date(2000, 3, 1), e=datetime(2000, 1, 3, 12, 0))   # noqa\n",
    "])\n",
    "print('Creating a simple spark dataframe:', df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ba71321a-b898-4e2a-b29b-d8d57a1f2d70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating a spark dataframe with an schema:\n",
      "DataFrame[a: bigint, b: double, c: string, d: date, e: timestamp]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Create a PySpark DataFrame with an explicit schema.\n",
    "df = spark.createDataFrame([\n",
    "    (1, 2., 'string1', date(2000, 1, 1), datetime(2000, 1, 1, 12, 0)),\n",
    "    (2, 3., 'string2', date(2000, 2, 1), datetime(2000, 1, 2, 12, 0)),\n",
    "    (3, 4., 'string3', date(2000, 3, 1), datetime(2000, 1, 3, 12, 0))\n",
    "], schema='a long, b double, c string, d date, e timestamp')\n",
    "print('Creating a spark dataframe with an schema:', df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c12b7689-2700-40e5-8767-91d0cb915a82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating a spark dataframe from pandas (Infering schema):\n",
      "DataFrame[a: bigint, b: double, c: string, d: date, e: timestamp]\n",
      "\n",
      "root\n",
      " |-- a: long (nullable = true)\n",
      " |-- b: double (nullable = true)\n",
      " |-- c: string (nullable = true)\n",
      " |-- d: date (nullable = true)\n",
      " |-- e: timestamp (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Create a PySpark DataFrame from a pandas DataFrame\n",
    "pandas_df = pd.DataFrame({\n",
    "    'a': [1, 2, 3],\n",
    "    'b': [2., 3., 4.],\n",
    "    'c': ['string1', 'string2', 'string3'],\n",
    "    'd': [date(2000, 1, 1), date(2000, 2, 1), date(2000, 3, 1)],\n",
    "    'e': [datetime(2000, 1, 1, 12, 0), datetime(2000, 1, 2, 12, 0), datetime(2000, 1, 3, 12, 0)]  # noqa\n",
    "})\n",
    "data_schema = types.StructType([\n",
    "    types.StructField('a', types.IntegerType(), True),\n",
    "    types.StructField('b', types.FloatType(), True),\n",
    "    types.StructField('c', types.StringType(), True),\n",
    "    types.StructField('d', types.DateType(), True),\n",
    "    types.StructField('e', types.TimestampType(), True),\n",
    "])\n",
    "df1 = spark.createDataFrame(pandas_df)\n",
    "print('Creating a spark dataframe from pandas (Infering schema):', df1)\n",
    "df1.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c778be18-e474-49b2-bc88-11047d6cf667",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+---+-------+----------+-------------------+\n",
      "|  a|  b|      c|         d|                  e|\n",
      "+---+---+-------+----------+-------------------+\n",
      "|  1|2.0|string1|2000-01-01|2000-01-01 12:00:00|\n",
      "|  2|3.0|string2|2000-02-01|2000-01-02 12:00:00|\n",
      "|  3|4.0|string3|2000-03-01|2000-01-03 12:00:00|\n",
      "+---+---+-------+----------+-------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "27f08e37-adee-4a89-b08a-f60668ebee28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating a spark dataframe from pandas (Explicit schema):\n",
      "DataFrame[a: bigint, b: double, c: string, d: date, e: timestamp]\n",
      "\n",
      "Object type\n",
      "<class 'pyspark.sql.dataframe.DataFrame'>\n",
      "\n",
      "root\n",
      " |-- a: integer (nullable = true)\n",
      " |-- b: float (nullable = true)\n",
      " |-- c: string (nullable = true)\n",
      " |-- d: date (nullable = true)\n",
      " |-- e: timestamp (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df2 = spark.createDataFrame(pandas_df, schema=data_schema)\n",
    "print('Creating a spark dataframe from pandas (Explicit schema):', df)\n",
    "print('Object type', type(df2))\n",
    "df2.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "208326bc-35c6-4483-8155-400c96b8138c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+---+-------+----------+-------------------+\n",
      "|  a|  b|      c|         d|                  e|\n",
      "+---+---+-------+----------+-------------------+\n",
      "|  1|2.0|string1|2000-01-01|2000-01-01 12:00:00|\n",
      "|  2|3.0|string2|2000-02-01|2000-01-02 12:00:00|\n",
      "|  3|4.0|string3|2000-03-01|2000-01-03 12:00:00|\n",
      "+---+---+-------+----------+-------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df2.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16c8164c-d3e7-45f6-9bd0-d261f875e171",
   "metadata": {},
   "source": [
    "## Viewing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "19389627-c0ed-4514-aabd-1d82982bef48",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.conf.set('spark.sql.repl.eagerEval.enabled', True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "352b4164-867b-4794-a008-ab5361971831",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border='1'>\n",
       "<tr><th>a</th><th>b</th><th>c</th><th>d</th><th>e</th></tr>\n",
       "<tr><td>1</td><td>2.0</td><td>string1</td><td>2000-01-01</td><td>2000-01-01 12:00:00</td></tr>\n",
       "<tr><td>2</td><td>3.0</td><td>string2</td><td>2000-02-01</td><td>2000-01-02 12:00:00</td></tr>\n",
       "<tr><td>3</td><td>4.0</td><td>string3</td><td>2000-03-01</td><td>2000-01-03 12:00:00</td></tr>\n",
       "</table>\n"
      ],
      "text/plain": [
       "+---+---+-------+----------+-------------------+\n",
       "|  a|  b|      c|         d|                  e|\n",
       "+---+---+-------+----------+-------------------+\n",
       "|  1|2.0|string1|2000-01-01|2000-01-01 12:00:00|\n",
       "|  2|3.0|string2|2000-02-01|2000-01-02 12:00:00|\n",
       "|  3|4.0|string3|2000-03-01|2000-01-03 12:00:00|\n",
       "+---+---+-------+----------+-------------------+"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f5bf9b70-ad13-420b-a200-9ef952a1fa73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-RECORD 0------------------\n",
      " a   | 1                   \n",
      " b   | 2.0                 \n",
      " c   | string1             \n",
      " d   | 2000-01-01          \n",
      " e   | 2000-01-01 12:00:00 \n",
      "only showing top 1 row\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df2.show(1, vertical=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c855af30-455e-4df4-89a2-a0434d939f54",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['a', 'b', 'c', 'd', 'e']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "bb45925e-a120-47c4-9e45-648f92e669d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- a: integer (nullable = true)\n",
      " |-- b: float (nullable = true)\n",
      " |-- c: string (nullable = true)\n",
      " |-- d: date (nullable = true)\n",
      " |-- e: timestamp (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df2.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "340d3ecf-261a-415e-b011-6d3394b76c0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+---+---+-------+\n",
      "|summary|  a|  b|      c|\n",
      "+-------+---+---+-------+\n",
      "|  count|  3|  3|      3|\n",
      "|   mean|2.0|3.0|   NULL|\n",
      "| stddev|1.0|1.0|   NULL|\n",
      "|    min|  1|2.0|string1|\n",
      "|    max|  3|4.0|string3|\n",
      "+-------+---+---+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df2.select(\"a\", \"b\", \"c\").describe().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ea91574c-e16c-4798-8590-91295adcd023",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+---+---+-------+\n",
      "|summary|  a|  b|      c|\n",
      "+-------+---+---+-------+\n",
      "|  count|  3|  3|      3|\n",
      "|   mean|2.0|3.0|   NULL|\n",
      "| stddev|1.0|1.0|   NULL|\n",
      "|    min|  1|2.0|string1|\n",
      "|    max|  3|4.0|string3|\n",
      "+-------+---+---+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df2.describe().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "01abaf86-4938-406a-b438-25cfa53acebd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border='1'>\n",
       "<tr><th>summary</th><th>a</th><th>b</th><th>c</th></tr>\n",
       "<tr><td>count</td><td>3</td><td>3</td><td>3</td></tr>\n",
       "<tr><td>mean</td><td>2.0</td><td>3.0</td><td>NULL</td></tr>\n",
       "<tr><td>stddev</td><td>1.0</td><td>1.0</td><td>NULL</td></tr>\n",
       "<tr><td>min</td><td>1</td><td>2.0</td><td>string1</td></tr>\n",
       "<tr><td>max</td><td>3</td><td>4.0</td><td>string3</td></tr>\n",
       "</table>\n"
      ],
      "text/plain": [
       "+-------+---+---+-------+\n",
       "|summary|  a|  b|      c|\n",
       "+-------+---+---+-------+\n",
       "|  count|  3|  3|      3|\n",
       "|   mean|2.0|3.0|   NULL|\n",
       "| stddev|1.0|1.0|   NULL|\n",
       "|    min|  1|2.0|string1|\n",
       "|    max|  3|4.0|string3|\n",
       "+-------+---+---+-------+"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "cc03764b-6660-4d63-8a05-a6932265b3c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(a=1, b=2.0, c='string1', d=datetime.date(2000, 1, 1), e=datetime.datetime(2000, 1, 1, 12, 0)),\n",
       " Row(a=2, b=3.0, c='string2', d=datetime.date(2000, 2, 1), e=datetime.datetime(2000, 1, 2, 12, 0)),\n",
       " Row(a=3, b=4.0, c='string3', d=datetime.date(2000, 3, 1), e=datetime.datetime(2000, 1, 3, 12, 0))]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# DataFrame.collect() collects the distributed data to the driver side as the local data in Python. \n",
    "# Note that this can throw an out-of-memory error when the dataset is too large to fit in the driver \n",
    "# side because it collects all the data from executors to the driver side.\n",
    "df2.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "04042533-b365-4283-bb55-b01ce8e0b960",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(a=1, b=2.0, c='string1', d=datetime.date(2000, 1, 1), e=datetime.datetime(2000, 1, 1, 12, 0)),\n",
       " Row(a=2, b=3.0, c='string2', d=datetime.date(2000, 2, 1), e=datetime.datetime(2000, 1, 2, 12, 0))]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# In order to avoid throwing an out-of-memory exception, use DataFrame.take() or DataFrame.tail().\n",
    "df2.take(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "64f61142-72f4-44fb-9eaa-a52889a289a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(a=2, b=3.0, c='string2', d=datetime.date(2000, 2, 1), e=datetime.datetime(2000, 1, 2, 12, 0)),\n",
       " Row(a=3, b=4.0, c='string3', d=datetime.date(2000, 3, 1), e=datetime.datetime(2000, 1, 3, 12, 0))]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2.tail(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b0d7fce9-b03d-4d24-9c03-4b9cf6d1264f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>a</th>\n",
       "      <th>b</th>\n",
       "      <th>c</th>\n",
       "      <th>d</th>\n",
       "      <th>e</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>string1</td>\n",
       "      <td>2000-01-01</td>\n",
       "      <td>2000-01-01 12:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>3.0</td>\n",
       "      <td>string2</td>\n",
       "      <td>2000-02-01</td>\n",
       "      <td>2000-01-02 12:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>4.0</td>\n",
       "      <td>string3</td>\n",
       "      <td>2000-03-01</td>\n",
       "      <td>2000-01-03 12:00:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   a    b        c           d                   e\n",
       "0  1  2.0  string1  2000-01-01 2000-01-01 12:00:00\n",
       "1  2  3.0  string2  2000-02-01 2000-01-02 12:00:00\n",
       "2  3  4.0  string3  2000-03-01 2000-01-03 12:00:00"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# PySpark DataFrame also provides the conversion back to a pandas DataFrame to leverage pandas API. \n",
    "# Note that toPandas also collects all data into the driver side that can easily cause an \n",
    "# out-of-memory-error when the data is too large to fit into the driver side.\n",
    "df2.toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2007767-e9a1-45a2-a8f6-f75acdfe9918",
   "metadata": {},
   "source": [
    "## Selecting and Accessing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "05cc675a-d340-440c-b62d-30d579619767",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border='1'>\n",
       "<tr><th>a</th><th>b</th><th>c</th><th>d</th><th>e</th></tr>\n",
       "<tr><td>1</td><td>2.0</td><td>string1</td><td>2000-01-01</td><td>2000-01-01 12:00:00</td></tr>\n",
       "<tr><td>2</td><td>3.0</td><td>string2</td><td>2000-02-01</td><td>2000-01-02 12:00:00</td></tr>\n",
       "<tr><td>3</td><td>4.0</td><td>string3</td><td>2000-03-01</td><td>2000-01-03 12:00:00</td></tr>\n",
       "</table>\n"
      ],
      "text/plain": [
       "+---+---+-------+----------+-------------------+\n",
       "|  a|  b|      c|         d|                  e|\n",
       "+---+---+-------+----------+-------------------+\n",
       "|  1|2.0|string1|2000-01-01|2000-01-01 12:00:00|\n",
       "|  2|3.0|string2|2000-02-01|2000-01-02 12:00:00|\n",
       "|  3|4.0|string3|2000-03-01|2000-01-03 12:00:00|\n",
       "+---+---+-------+----------+-------------------+"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "89e29122-a9b3-4282-9a35-0d75544e6710",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Column<'a'>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "93bff202-7b6a-4262-9808-21e69e4b6135",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pyspark.sql.column.Column'>\n",
      "<class 'pyspark.sql.column.Column'>\n",
      "<class 'pyspark.sql.column.Column'>\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(type(df.c), type(upper(df.c)), type(df.c.isNull()))\n",
    "type(df.c) == type(upper(df.c)) == type(df.c.isNull())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "7f6866e1-0d6d-4329-809e-88430d41735a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+\n",
      "|      c|\n",
      "+-------+\n",
      "|string1|\n",
      "|string2|\n",
      "|string3|\n",
      "+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select(df.c).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "47b0e6f1-6b3d-455f-99ad-ae286fe2c9a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+---+-------+----------+-------------------+-------+\n",
      "|  a|  b|      c|         d|                  e|upper_c|\n",
      "+---+---+-------+----------+-------------------+-------+\n",
      "|  1|2.0|string1|2000-01-01|2000-01-01 12:00:00|STRING1|\n",
      "|  2|3.0|string2|2000-02-01|2000-01-02 12:00:00|STRING2|\n",
      "|  3|4.0|string3|2000-03-01|2000-01-03 12:00:00|STRING3|\n",
      "+---+---+-------+----------+-------------------+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Assign new Column instance.\n",
    "df.withColumn('upper_c', upper(df.c)).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "06b44168-d586-405e-a58a-71be493e0268",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+---+-------+----------+-------------------+\n",
      "|  a|  b|      c|         d|                  e|\n",
      "+---+---+-------+----------+-------------------+\n",
      "|  1|2.0|string1|2000-01-01|2000-01-01 12:00:00|\n",
      "+---+---+-------+----------+-------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# To select a subset of rows, use DataFrame.filter().\n",
    "df.filter(df.a == 1).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a030df2f-f3d7-4f5f-abca-c1258a6c1d9f",
   "metadata": {},
   "source": [
    "## Applying a Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "d01922ea-2a1e-4236-a8bb-951a49801200",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+\n",
      "|pandas_plus_one(a)|\n",
      "+------------------+\n",
      "|                 2|\n",
      "|                 3|\n",
      "|                 4|\n",
      "+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "@pandas_udf('long')\n",
    "def pandas_plus_one(series: pd.Series) -> pd.Series:\n",
    "    # Simply plus one by using pandas Series.\n",
    "    return series + 1\n",
    "\n",
    "df.select(pandas_plus_one(df.a)).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "e7bc3ec5-1314-4ccb-95b2-e66745e7a037",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+\n",
      "|upper(c)|\n",
      "+--------+\n",
      "| STRING1|\n",
      "| STRING2|\n",
      "| STRING3|\n",
      "+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select(upper(df.c)).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "a44084f0-b128-4e9b-b112-70de1c9362c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+---+-------+----------+-------------------+\n",
      "|  a|  b|      c|         d|                  e|\n",
      "+---+---+-------+----------+-------------------+\n",
      "|  1|2.0|string1|2000-01-01|2000-01-01 12:00:00|\n",
      "+---+---+-------+----------+-------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# DataFrame.mapInPandas allows users directly use the APIs in a pandas DataFrame \n",
    "# without any restrictions such as the result length.\n",
    "def pandas_filter_func(iterator):\n",
    "    for pandas_df in iterator:\n",
    "        yield pandas_df[pandas_df.a == 1]\n",
    "\n",
    "df.mapInPandas(pandas_filter_func, schema=df.schema).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f6f78b8-76c7-4e04-bd49-8613b353fbaf",
   "metadata": {},
   "source": [
    "### Another example\n",
    "\n",
    "![PandasUDF_applyInPandas_and_mapInPandas](images/PandasUDF_applyInPandas_and_mapInPandas.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "8f6dd962-167b-4dcc-8aca-1b9b7bef3e6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5000000, 4)\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border='1'>\n",
       "<tr><th>id</th><th>device_id</th><th>trip_id</th><th>sensor_reading</th></tr>\n",
       "<tr><td>0</td><td>7085</td><td>15</td><td>565.3351721177589</td></tr>\n",
       "<tr><td>1</td><td>5614</td><td>17</td><td>480.9863031229702</td></tr>\n",
       "<tr><td>2</td><td>9443</td><td>0</td><td>410.92721186155615</td></tr>\n",
       "<tr><td>3</td><td>6285</td><td>41</td><td>654.0700823683391</td></tr>\n",
       "<tr><td>4</td><td>3706</td><td>29</td><td>959.4971241264645</td></tr>\n",
       "<tr><td>5</td><td>5069</td><td>19</td><td>765.6619907260629</td></tr>\n",
       "<tr><td>6</td><td>4725</td><td>12</td><td>119.47958576777484</td></tr>\n",
       "<tr><td>7</td><td>6267</td><td>1</td><td>578.3716312782248</td></tr>\n",
       "<tr><td>8</td><td>5814</td><td>10</td><td>966.2220829633112</td></tr>\n",
       "<tr><td>9</td><td>198</td><td>18</td><td>164.21666364139497</td></tr>\n",
       "<tr><td>10</td><td>7370</td><td>10</td><td>755.6475140344637</td></tr>\n",
       "<tr><td>11</td><td>2465</td><td>2</td><td>822.3523264326516</td></tr>\n",
       "<tr><td>12</td><td>8860</td><td>37</td><td>622.801380386189</td></tr>\n",
       "<tr><td>13</td><td>1005</td><td>46</td><td>187.84774592802677</td></tr>\n",
       "<tr><td>14</td><td>1464</td><td>5</td><td>690.3170175539176</td></tr>\n",
       "<tr><td>15</td><td>5002</td><td>25</td><td>296.011359890763</td></tr>\n",
       "<tr><td>16</td><td>8794</td><td>27</td><td>429.2404846904279</td></tr>\n",
       "<tr><td>17</td><td>3958</td><td>38</td><td>285.3255925968933</td></tr>\n",
       "<tr><td>18</td><td>9066</td><td>11</td><td>112.07207608649693</td></tr>\n",
       "<tr><td>19</td><td>9225</td><td>0</td><td>806.6267444620021</td></tr>\n",
       "</table>\n",
       "only showing top 20 rows\n"
      ],
      "text/plain": [
       "+---+---------+-------+------------------+\n",
       "| id|device_id|trip_id|    sensor_reading|\n",
       "+---+---------+-------+------------------+\n",
       "|  0|     7085|     15| 565.3351721177589|\n",
       "|  1|     5614|     17| 480.9863031229702|\n",
       "|  2|     9443|      0|410.92721186155615|\n",
       "|  3|     6285|     41| 654.0700823683391|\n",
       "|  4|     3706|     29| 959.4971241264645|\n",
       "|  5|     5069|     19| 765.6619907260629|\n",
       "|  6|     4725|     12|119.47958576777484|\n",
       "|  7|     6267|      1| 578.3716312782248|\n",
       "|  8|     5814|     10| 966.2220829633112|\n",
       "|  9|      198|     18|164.21666364139497|\n",
       "| 10|     7370|     10| 755.6475140344637|\n",
       "| 11|     2465|      2| 822.3523264326516|\n",
       "| 12|     8860|     37|  622.801380386189|\n",
       "| 13|     1005|     46|187.84774592802677|\n",
       "| 14|     1464|      5| 690.3170175539176|\n",
       "| 15|     5002|     25|  296.011359890763|\n",
       "| 16|     8794|     27| 429.2404846904279|\n",
       "| 17|     3958|     38| 285.3255925968933|\n",
       "| 18|     9066|     11|112.07207608649693|\n",
       "| 19|     9225|      0| 806.6267444620021|\n",
       "+---+---------+-------+------------------+\n",
       "only showing top 20 rows"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def generate_initial_df(num_rows, num_devices, num_trips):\n",
    "   return (\n",
    "       spark.range(num_rows)\n",
    "       .withColumn('device_id', (rand()*num_devices).cast('int'))\n",
    "       .withColumn('trip_id', (rand()*num_trips).cast('int'))\n",
    "       .withColumn('sensor_reading', (rand()*1000))\n",
    "       # .drop('id')\n",
    "   )\n",
    "\n",
    "df_origin = generate_initial_df(5000000, 10000, 50)\n",
    "print((df_origin.count(), len(df_origin.columns)))\n",
    "df_origin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "fd5f3389-907e-4c37-9647-4501c246b6d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border='1'>\n",
       "<tr><th>id</th><th>device_id</th><th>trip_id</th><th>sensor_reading</th><th>sqrt_reading</th></tr>\n",
       "<tr><td>0</td><td>7085</td><td>15</td><td>565.3351721177589</td><td>23.77677800118761</td></tr>\n",
       "<tr><td>1</td><td>5614</td><td>17</td><td>480.9863031229702</td><td>21.931399935320368</td></tr>\n",
       "<tr><td>2</td><td>9443</td><td>0</td><td>410.92721186155615</td><td>20.271339666177866</td></tr>\n",
       "<tr><td>3</td><td>6285</td><td>41</td><td>654.0700823683391</td><td>25.57479388711352</td></tr>\n",
       "<tr><td>4</td><td>3706</td><td>29</td><td>959.4971241264645</td><td>30.97575058213222</td></tr>\n",
       "<tr><td>5</td><td>5069</td><td>19</td><td>765.6619907260629</td><td>27.670597946666472</td></tr>\n",
       "<tr><td>6</td><td>4725</td><td>12</td><td>119.47958576777484</td><td>10.930671789408684</td></tr>\n",
       "<tr><td>7</td><td>6267</td><td>1</td><td>578.3716312782248</td><td>24.049358230069775</td></tr>\n",
       "<tr><td>8</td><td>5814</td><td>10</td><td>966.2220829633112</td><td>31.084113031632594</td></tr>\n",
       "<tr><td>9</td><td>198</td><td>18</td><td>164.21666364139497</td><td>12.8147049767599</td></tr>\n",
       "<tr><td>10</td><td>7370</td><td>10</td><td>755.6475140344637</td><td>27.489043527093912</td></tr>\n",
       "<tr><td>11</td><td>2465</td><td>2</td><td>822.3523264326516</td><td>28.676686113159093</td></tr>\n",
       "<tr><td>12</td><td>8860</td><td>37</td><td>622.801380386189</td><td>24.955988868129207</td></tr>\n",
       "<tr><td>13</td><td>1005</td><td>46</td><td>187.84774592802677</td><td>13.705755941502343</td></tr>\n",
       "<tr><td>14</td><td>1464</td><td>5</td><td>690.3170175539176</td><td>26.273884706185296</td></tr>\n",
       "<tr><td>15</td><td>5002</td><td>25</td><td>296.011359890763</td><td>17.20498067103718</td></tr>\n",
       "<tr><td>16</td><td>8794</td><td>27</td><td>429.2404846904279</td><td>20.718119718990618</td></tr>\n",
       "<tr><td>17</td><td>3958</td><td>38</td><td>285.3255925968933</td><td>16.89158348399857</td></tr>\n",
       "<tr><td>18</td><td>9066</td><td>11</td><td>112.07207608649693</td><td>10.586409971586068</td></tr>\n",
       "<tr><td>19</td><td>9225</td><td>0</td><td>806.6267444620021</td><td>28.401175054247354</td></tr>\n",
       "</table>\n",
       "only showing top 20 rows\n"
      ],
      "text/plain": [
       "+---+---------+-------+------------------+------------------+\n",
       "| id|device_id|trip_id|    sensor_reading|      sqrt_reading|\n",
       "+---+---------+-------+------------------+------------------+\n",
       "|  0|     7085|     15| 565.3351721177589| 23.77677800118761|\n",
       "|  1|     5614|     17| 480.9863031229702|21.931399935320368|\n",
       "|  2|     9443|      0|410.92721186155615|20.271339666177866|\n",
       "|  3|     6285|     41| 654.0700823683391| 25.57479388711352|\n",
       "|  4|     3706|     29| 959.4971241264645| 30.97575058213222|\n",
       "|  5|     5069|     19| 765.6619907260629|27.670597946666472|\n",
       "|  6|     4725|     12|119.47958576777484|10.930671789408684|\n",
       "|  7|     6267|      1| 578.3716312782248|24.049358230069775|\n",
       "|  8|     5814|     10| 966.2220829633112|31.084113031632594|\n",
       "|  9|      198|     18|164.21666364139497|  12.8147049767599|\n",
       "| 10|     7370|     10| 755.6475140344637|27.489043527093912|\n",
       "| 11|     2465|      2| 822.3523264326516|28.676686113159093|\n",
       "| 12|     8860|     37|  622.801380386189|24.955988868129207|\n",
       "| 13|     1005|     46|187.84774592802677|13.705755941502343|\n",
       "| 14|     1464|      5| 690.3170175539176|26.273884706185296|\n",
       "| 15|     5002|     25|  296.011359890763| 17.20498067103718|\n",
       "| 16|     8794|     27| 429.2404846904279|20.718119718990618|\n",
       "| 17|     3958|     38| 285.3255925968933| 16.89158348399857|\n",
       "| 18|     9066|     11|112.07207608649693|10.586409971586068|\n",
       "| 19|     9225|      0| 806.6267444620021|28.401175054247354|\n",
       "+---+---------+-------+------------------+------------------+\n",
       "only showing top 20 rows"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# pandas_udf\n",
    "@pandas_udf('double')\n",
    "def calculate_sqrt(sensor_reading: pd.Series) -> pd.Series:\n",
    "   return sensor_reading.apply(lambda x: x**0.5)\n",
    "\n",
    "df_pandas_udf = df_origin.withColumn('sqrt_reading', calculate_sqrt(col('sensor_reading')))\n",
    "df_pandas_udf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "9af3d42c-0020-4798-9592-4e18865d0ded",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border='1'>\n",
       "<tr><th>device_id</th><th>id</th><th>trip_id</th><th>sensor_reading</th><th>sqrt_reading</th></tr>\n",
       "<tr><td>31</td><td>4999466</td><td>[21, 23, 1, 24, 4...</td><td>503</td><td>21</td></tr>\n",
       "<tr><td>34</td><td>4997892</td><td>[12, 21, 9, 19, 4...</td><td>492</td><td>20</td></tr>\n",
       "<tr><td>53</td><td>4996226</td><td>[32, 23, 23, 36, ...</td><td>497</td><td>21</td></tr>\n",
       "<tr><td>65</td><td>4997875</td><td>[24, 38, 48, 36, ...</td><td>495</td><td>21</td></tr>\n",
       "<tr><td>78</td><td>4998781</td><td>[33, 21, 30, 4, 1...</td><td>505</td><td>21</td></tr>\n",
       "<tr><td>85</td><td>4990461</td><td>[10, 41, 29, 24, ...</td><td>504</td><td>21</td></tr>\n",
       "<tr><td>108</td><td>4992992</td><td>[1, 35, 21, 45, 4...</td><td>498</td><td>21</td></tr>\n",
       "<tr><td>133</td><td>4989746</td><td>[7, 14, 19, 34, 2...</td><td>452</td><td>19</td></tr>\n",
       "<tr><td>137</td><td>4999313</td><td>[28, 27, 29, 35, ...</td><td>518</td><td>21</td></tr>\n",
       "<tr><td>148</td><td>4975991</td><td>[10, 6, 24, 1, 16...</td><td>506</td><td>21</td></tr>\n",
       "<tr><td>155</td><td>4999842</td><td>[2, 5, 46, 44, 11...</td><td>502</td><td>21</td></tr>\n",
       "<tr><td>193</td><td>4989764</td><td>[40, 13, 13, 45, ...</td><td>507</td><td>21</td></tr>\n",
       "<tr><td>211</td><td>4998664</td><td>[19, 40, 35, 44, ...</td><td>493</td><td>20</td></tr>\n",
       "<tr><td>243</td><td>4962195</td><td>[47, 5, 22, 43, 3...</td><td>511</td><td>21</td></tr>\n",
       "<tr><td>251</td><td>4998879</td><td>[20, 46, 2, 34, 4...</td><td>488</td><td>20</td></tr>\n",
       "<tr><td>255</td><td>4995888</td><td>[21, 17, 42, 4, 3...</td><td>501</td><td>21</td></tr>\n",
       "<tr><td>296</td><td>4965704</td><td>[32, 8, 45, 27, 2...</td><td>511</td><td>21</td></tr>\n",
       "<tr><td>321</td><td>4995410</td><td>[45, 15, 3, 25, 0...</td><td>472</td><td>20</td></tr>\n",
       "<tr><td>322</td><td>4996005</td><td>[12, 42, 41, 42, ...</td><td>541</td><td>22</td></tr>\n",
       "<tr><td>362</td><td>4991677</td><td>[9, 31, 16, 18, 2...</td><td>499</td><td>21</td></tr>\n",
       "</table>\n",
       "only showing top 20 rows\n"
      ],
      "text/plain": [
       "+---------+-------+--------------------+--------------+------------+\n",
       "|device_id|     id|             trip_id|sensor_reading|sqrt_reading|\n",
       "+---------+-------+--------------------+--------------+------------+\n",
       "|       31|4999466|[21, 23, 1, 24, 4...|           503|          21|\n",
       "|       34|4997892|[12, 21, 9, 19, 4...|           492|          20|\n",
       "|       53|4996226|[32, 23, 23, 36, ...|           497|          21|\n",
       "|       65|4997875|[24, 38, 48, 36, ...|           495|          21|\n",
       "|       78|4998781|[33, 21, 30, 4, 1...|           505|          21|\n",
       "|       85|4990461|[10, 41, 29, 24, ...|           504|          21|\n",
       "|      108|4992992|[1, 35, 21, 45, 4...|           498|          21|\n",
       "|      133|4989746|[7, 14, 19, 34, 2...|           452|          19|\n",
       "|      137|4999313|[28, 27, 29, 35, ...|           518|          21|\n",
       "|      148|4975991|[10, 6, 24, 1, 16...|           506|          21|\n",
       "|      155|4999842|[2, 5, 46, 44, 11...|           502|          21|\n",
       "|      193|4989764|[40, 13, 13, 45, ...|           507|          21|\n",
       "|      211|4998664|[19, 40, 35, 44, ...|           493|          20|\n",
       "|      243|4962195|[47, 5, 22, 43, 3...|           511|          21|\n",
       "|      251|4998879|[20, 46, 2, 34, 4...|           488|          20|\n",
       "|      255|4995888|[21, 17, 42, 4, 3...|           501|          21|\n",
       "|      296|4965704|[32, 8, 45, 27, 2...|           511|          21|\n",
       "|      321|4995410|[45, 15, 3, 25, 0...|           472|          20|\n",
       "|      322|4996005|[12, 42, 41, 42, ...|           541|          22|\n",
       "|      362|4991677|[9, 31, 16, 18, 2...|           499|          21|\n",
       "+---------+-------+--------------------+--------------+------------+\n",
       "only showing top 20 rows"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# applyInPandas\n",
    "def denormalize(pdf: pd.DataFrame) -> pd.DataFrame:\n",
    "  aggregated_df = pdf.groupby('device_id', as_index=False).agg({\n",
    "      'id': 'max',\n",
    "      'trip_id': lambda x: list(x), \n",
    "      'sensor_reading': 'mean', \n",
    "      'sqrt_reading': 'mean'\n",
    "  })\n",
    "  return aggregated_df\n",
    "\n",
    "expected_schema = 'device_id int, id int, trip_id array<int>, sensor_reading long, sqrt_reading long'\n",
    "df_applyinpandas = df_pandas_udf.groupBy('device_id').applyInPandas(denormalize, schema=expected_schema)\n",
    "df_applyinpandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "4aab476d-d542-4661-afb6-0d7e296c47a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>b</th>\n",
       "      <th>c</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>a</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>A</th>\n",
       "      <td>[1, 2]</td>\n",
       "      <td>[3, 3]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>B</th>\n",
       "      <td>[5, 5, 4]</td>\n",
       "      <td>[3, 4, 4]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>C</th>\n",
       "      <td>[6]</td>\n",
       "      <td>[4]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           b          c\n",
       "a                      \n",
       "A     [1, 2]     [3, 3]\n",
       "B  [5, 5, 4]  [3, 4, 4]\n",
       "C        [6]        [4]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Simple Group list for pandas:\n",
    "dfx = pd.DataFrame( {\n",
    "    'a':['A','A','B','B','B','C'], \n",
    "    'b':[1,2,5,5,4,6],\n",
    "    'c':[3,3,3,4,4,4]})\n",
    "dfx.groupby('a').agg(lambda x: list(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "09d47d86-b50c-4cf3-9711-e1d8d57a45bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border='1'>\n",
       "<tr><th>device_id</th><th>id</th><th>trip_id</th><th>sensor_reading</th><th>sqrt_reading</th></tr>\n",
       "<tr><td>31</td><td>4999466</td><td>21</td><td>503</td><td>21</td></tr>\n",
       "<tr><td>31</td><td>4999466</td><td>23</td><td>503</td><td>21</td></tr>\n",
       "<tr><td>31</td><td>4999466</td><td>1</td><td>503</td><td>21</td></tr>\n",
       "<tr><td>31</td><td>4999466</td><td>24</td><td>503</td><td>21</td></tr>\n",
       "<tr><td>31</td><td>4999466</td><td>43</td><td>503</td><td>21</td></tr>\n",
       "<tr><td>31</td><td>4999466</td><td>23</td><td>503</td><td>21</td></tr>\n",
       "<tr><td>31</td><td>4999466</td><td>17</td><td>503</td><td>21</td></tr>\n",
       "<tr><td>31</td><td>4999466</td><td>37</td><td>503</td><td>21</td></tr>\n",
       "<tr><td>31</td><td>4999466</td><td>29</td><td>503</td><td>21</td></tr>\n",
       "<tr><td>31</td><td>4999466</td><td>9</td><td>503</td><td>21</td></tr>\n",
       "<tr><td>31</td><td>4999466</td><td>48</td><td>503</td><td>21</td></tr>\n",
       "<tr><td>31</td><td>4999466</td><td>45</td><td>503</td><td>21</td></tr>\n",
       "<tr><td>31</td><td>4999466</td><td>0</td><td>503</td><td>21</td></tr>\n",
       "<tr><td>31</td><td>4999466</td><td>36</td><td>503</td><td>21</td></tr>\n",
       "<tr><td>31</td><td>4999466</td><td>40</td><td>503</td><td>21</td></tr>\n",
       "<tr><td>31</td><td>4999466</td><td>1</td><td>503</td><td>21</td></tr>\n",
       "<tr><td>31</td><td>4999466</td><td>27</td><td>503</td><td>21</td></tr>\n",
       "<tr><td>31</td><td>4999466</td><td>10</td><td>503</td><td>21</td></tr>\n",
       "<tr><td>31</td><td>4999466</td><td>30</td><td>503</td><td>21</td></tr>\n",
       "<tr><td>31</td><td>4999466</td><td>5</td><td>503</td><td>21</td></tr>\n",
       "</table>\n",
       "only showing top 20 rows\n"
      ],
      "text/plain": [
       "+---------+-------+-------+--------------+------------+\n",
       "|device_id|     id|trip_id|sensor_reading|sqrt_reading|\n",
       "+---------+-------+-------+--------------+------------+\n",
       "|       31|4999466|     21|           503|          21|\n",
       "|       31|4999466|     23|           503|          21|\n",
       "|       31|4999466|      1|           503|          21|\n",
       "|       31|4999466|     24|           503|          21|\n",
       "|       31|4999466|     43|           503|          21|\n",
       "|       31|4999466|     23|           503|          21|\n",
       "|       31|4999466|     17|           503|          21|\n",
       "|       31|4999466|     37|           503|          21|\n",
       "|       31|4999466|     29|           503|          21|\n",
       "|       31|4999466|      9|           503|          21|\n",
       "|       31|4999466|     48|           503|          21|\n",
       "|       31|4999466|     45|           503|          21|\n",
       "|       31|4999466|      0|           503|          21|\n",
       "|       31|4999466|     36|           503|          21|\n",
       "|       31|4999466|     40|           503|          21|\n",
       "|       31|4999466|      1|           503|          21|\n",
       "|       31|4999466|     27|           503|          21|\n",
       "|       31|4999466|     10|           503|          21|\n",
       "|       31|4999466|     30|           503|          21|\n",
       "|       31|4999466|      5|           503|          21|\n",
       "+---------+-------+-------+--------------+------------+\n",
       "only showing top 20 rows"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# mapInPandas\n",
    "def renormalize(itr: Iterator[pd.DataFrame]) -> Iterator[pd.DataFrame]:\n",
    "   for pdf in itr:\n",
    "       # Unpack the list of values from the trip_id column into their own rows\n",
    "       pdf = pdf.explode('trip_id')\n",
    "       yield pdf\n",
    "\n",
    "expected_schema = 'device_id int, id int, trip_id int, sensor_reading long, sqrt_reading long'\n",
    "df_mapinpandas = df_applyinpandas.mapInPandas(renormalize, schema=expected_schema)\n",
    "df_mapinpandas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c1039ff-c575-48b0-bdb3-4695bb12b60a",
   "metadata": {},
   "source": [
    "## Grouping Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "d8515db8-6cce-4eea-853e-253f58ccae34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- color: string (nullable = true)\n",
      " |-- fruit: string (nullable = true)\n",
      " |-- v1: long (nullable = true)\n",
      " |-- v2: long (nullable = true)\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border='1'>\n",
       "<tr><th>color</th><th>fruit</th><th>v1</th><th>v2</th></tr>\n",
       "<tr><td>red</td><td>banana</td><td>1</td><td>10</td></tr>\n",
       "<tr><td>blue</td><td>banana</td><td>2</td><td>20</td></tr>\n",
       "<tr><td>red</td><td>carrot</td><td>3</td><td>30</td></tr>\n",
       "<tr><td>blue</td><td>grape</td><td>4</td><td>40</td></tr>\n",
       "<tr><td>red</td><td>carrot</td><td>5</td><td>50</td></tr>\n",
       "<tr><td>black</td><td>carrot</td><td>6</td><td>60</td></tr>\n",
       "<tr><td>red</td><td>banana</td><td>7</td><td>70</td></tr>\n",
       "<tr><td>red</td><td>grape</td><td>8</td><td>80</td></tr>\n",
       "</table>\n"
      ],
      "text/plain": [
       "+-----+------+---+---+\n",
       "|color| fruit| v1| v2|\n",
       "+-----+------+---+---+\n",
       "|  red|banana|  1| 10|\n",
       "| blue|banana|  2| 20|\n",
       "|  red|carrot|  3| 30|\n",
       "| blue| grape|  4| 40|\n",
       "|  red|carrot|  5| 50|\n",
       "|black|carrot|  6| 60|\n",
       "|  red|banana|  7| 70|\n",
       "|  red| grape|  8| 80|\n",
       "+-----+------+---+---+"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = spark.createDataFrame([\n",
    "    ['red', 'banana', 1, 10], ['blue', 'banana', 2, 20], ['red', 'carrot', 3, 30],\n",
    "    ['blue', 'grape', 4, 40], ['red', 'carrot', 5, 50], ['black', 'carrot', 6, 60],\n",
    "    ['red', 'banana', 7, 70], ['red', 'grape', 8, 80]], schema=['color', 'fruit', 'v1', 'v2'])\n",
    "df.printSchema()\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "8b0db568-b65f-4643-9d43-c1670b7498d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- color: string (nullable = true)\n",
      " |-- avg(v1): double (nullable = true)\n",
      " |-- avg(v2): double (nullable = true)\n",
      "\n",
      "+-----+-------+-------+\n",
      "|color|avg(v1)|avg(v2)|\n",
      "+-----+-------+-------+\n",
      "|  red|    4.8|   48.0|\n",
      "| blue|    3.0|   30.0|\n",
      "|black|    6.0|   60.0|\n",
      "+-----+-------+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df1 = df.groupby('color').avg()\n",
    "df1.printSchema()\n",
    "df1.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "abb0d0b8-99e7-4913-86d2-6ef1b664887d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- color: string (nullable = true)\n",
      " |-- fruit: string (nullable = true)\n",
      " |-- v1: long (nullable = true)\n",
      " |-- v2: long (nullable = true)\n",
      "\n",
      "+-----+------+---+---+\n",
      "|color| fruit| v1| v2|\n",
      "+-----+------+---+---+\n",
      "|black|carrot|  0| 60|\n",
      "| blue|banana| -1| 20|\n",
      "| blue| grape|  1| 40|\n",
      "|  red|banana| -3| 10|\n",
      "|  red|carrot| -1| 30|\n",
      "|  red|carrot|  0| 50|\n",
      "|  red|banana|  2| 70|\n",
      "|  red| grape|  3| 80|\n",
      "+-----+------+---+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def plus_mean(pandas_df):\n",
    "    return pandas_df.assign(v1=pandas_df.v1 - pandas_df.v1.mean())\n",
    "\n",
    "df1 = df.groupby('color').applyInPandas(plus_mean, schema=df.schema)\n",
    "df1.printSchema()\n",
    "df1.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0103f0e0-0a8a-46fe-9a08-5986b26796ee",
   "metadata": {},
   "source": [
    "### Co-grouping and applying a function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "6b571902-9b4d-4f70-8158-c0866a6e018b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = spark.createDataFrame(\n",
    "    [(20000101, 1, 1.0), (20000101, 2, 2.0), (20000102, 1, 3.0), (20000102, 2, 4.0)],\n",
    "    ('time', 'id', 'v1'))\n",
    "\n",
    "df2 = spark.createDataFrame(\n",
    "    [(20000101, 1, 'x'), (20000101, 2, 'y')],\n",
    "    ('time', 'id', 'v2'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "9f3bf144-cba4-4696-a5e1-4524e84a6d9e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border='1'>\n",
       "<tr><th>time</th><th>id</th><th>v1</th></tr>\n",
       "<tr><td>20000101</td><td>1</td><td>1.0</td></tr>\n",
       "<tr><td>20000101</td><td>2</td><td>2.0</td></tr>\n",
       "<tr><td>20000102</td><td>1</td><td>3.0</td></tr>\n",
       "<tr><td>20000102</td><td>2</td><td>4.0</td></tr>\n",
       "</table>\n"
      ],
      "text/plain": [
       "+--------+---+---+\n",
       "|    time| id| v1|\n",
       "+--------+---+---+\n",
       "|20000101|  1|1.0|\n",
       "|20000101|  2|2.0|\n",
       "|20000102|  1|3.0|\n",
       "|20000102|  2|4.0|\n",
       "+--------+---+---+"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "7490662c-13b2-4575-ac2d-241acfe69e7d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border='1'>\n",
       "<tr><th>time</th><th>id</th><th>v2</th></tr>\n",
       "<tr><td>20000101</td><td>1</td><td>x</td></tr>\n",
       "<tr><td>20000101</td><td>2</td><td>y</td></tr>\n",
       "</table>\n"
      ],
      "text/plain": [
       "+--------+---+---+\n",
       "|    time| id| v2|\n",
       "+--------+---+---+\n",
       "|20000101|  1|  x|\n",
       "|20000101|  2|  y|\n",
       "+--------+---+---+"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "95652c3c-ade9-4c57-9134-8a7d7b9d56e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+---+---+----+\n",
      "|    time| id| v1|  v2|\n",
      "+--------+---+---+----+\n",
      "|20000101|  1|1.0|   x|\n",
      "|20000102|  1|3.0|NULL|\n",
      "|20000101|  2|2.0|   y|\n",
      "|20000102|  2|4.0|NULL|\n",
      "+--------+---+---+----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def merge_ordered(l, r):\n",
    "    return pd.merge_ordered(l, r)\n",
    "\n",
    "(df1.groupby('id')\n",
    "    .cogroup(df2.groupby('id'))\n",
    "    .applyInPandas(merge_ordered, \n",
    "                   schema='time int, id int, v1 double, v2 string')\n",
    ").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5a57164-7a56-4350-b3d7-424ce6236369",
   "metadata": {},
   "source": [
    "## Getting Data In/Out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "5e9ee31c-5043-4519-a7dd-585f1219805d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border='1'>\n",
       "<tr><th>color</th><th>fruit</th><th>v1</th><th>v2</th></tr>\n",
       "<tr><td>red</td><td>banana</td><td>1</td><td>10</td></tr>\n",
       "<tr><td>blue</td><td>banana</td><td>2</td><td>20</td></tr>\n",
       "<tr><td>red</td><td>carrot</td><td>3</td><td>30</td></tr>\n",
       "<tr><td>blue</td><td>grape</td><td>4</td><td>40</td></tr>\n",
       "<tr><td>red</td><td>carrot</td><td>5</td><td>50</td></tr>\n",
       "<tr><td>black</td><td>carrot</td><td>6</td><td>60</td></tr>\n",
       "<tr><td>red</td><td>banana</td><td>7</td><td>70</td></tr>\n",
       "<tr><td>red</td><td>grape</td><td>8</td><td>80</td></tr>\n",
       "</table>\n"
      ],
      "text/plain": [
       "DataFrame[color: string, fruit: string, v1: bigint, v2: bigint]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c058ef7a-7ca9-438b-b30b-cbc0e7c012db",
   "metadata": {},
   "source": [
    "### CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "fdf9b8aa-f189-4add-b4b3-92ae21030f2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+------+---+---+\n",
      "|color| fruit| v1| v2|\n",
      "+-----+------+---+---+\n",
      "|black|carrot|  6| 60|\n",
      "| blue|banana|  2| 20|\n",
      "|  red|banana|  1| 10|\n",
      "|  red|carrot|  3| 30|\n",
      "| blue| grape|  4| 40|\n",
      "|  red|carrot|  5| 50|\n",
      "|  red|banana|  7| 70|\n",
      "|  red| grape|  8| 80|\n",
      "+-----+------+---+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.write.csv('files/foo.csv', header=True, mode=\"overwrite\")\n",
    "spark.read.csv('files/foo.csv', header=True).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1da5e87b-0271-4276-9d67-7b87a8a9473e",
   "metadata": {},
   "source": [
    "### Parquet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "23992708-7bb9-4d60-bd27-3c2f46e05e21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+------+---+---+\n",
      "|color| fruit| v1| v2|\n",
      "+-----+------+---+---+\n",
      "|black|carrot|  6| 60|\n",
      "| blue|banana|  2| 20|\n",
      "| blue| grape|  4| 40|\n",
      "|  red|carrot|  5| 50|\n",
      "|  red|banana|  7| 70|\n",
      "|  red|banana|  1| 10|\n",
      "|  red|carrot|  3| 30|\n",
      "|  red| grape|  8| 80|\n",
      "+-----+------+---+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.write.parquet('files/bar.parquet', mode=\"overwrite\")\n",
    "spark.read.parquet('files/bar.parquet').show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33f84f58-31b4-4e6e-b0dd-d0076ad075c6",
   "metadata": {},
   "source": [
    "### ORC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "66ea4e89-ddf2-4d25-8ddb-2d322d02b730",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+------+---+---+\n",
      "|color| fruit| v1| v2|\n",
      "+-----+------+---+---+\n",
      "|  red|banana|  7| 70|\n",
      "|  red| grape|  8| 80|\n",
      "|black|carrot|  6| 60|\n",
      "| blue|banana|  2| 20|\n",
      "|  red|banana|  1| 10|\n",
      "|  red|carrot|  5| 50|\n",
      "|  red|carrot|  3| 30|\n",
      "| blue| grape|  4| 40|\n",
      "+-----+------+---+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.write.orc('files/zoo.orc', mode=\"overwrite\")\n",
    "spark.read.orc('files/zoo.orc').show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46f84357-a15a-4710-bc5f-4dd6fc4c0c51",
   "metadata": {},
   "source": [
    "## Working with SQL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "1ddbf370-d124-40af-b500-8123f359a00a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+------+---+---+\n",
      "|color| fruit| v1| v2|\n",
      "+-----+------+---+---+\n",
      "|  red|banana|  1| 10|\n",
      "| blue|banana|  2| 20|\n",
      "|  red|carrot|  3| 30|\n",
      "| blue| grape|  4| 40|\n",
      "|  red|carrot|  5| 50|\n",
      "|black|carrot|  6| 60|\n",
      "|  red|banana|  7| 70|\n",
      "|  red| grape|  8| 80|\n",
      "+-----+------+---+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.createOrReplaceTempView(\"tableA\")\n",
    "spark.sql(\"SELECT * from tableA\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "72fe5bee-47cf-406c-be17-ee3808a25b09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+\n",
      "|count(1)|\n",
      "+--------+\n",
      "|       8|\n",
      "+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"SELECT count(*) from tableA\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "fdf15bfd-dc87-4a82-9f3e-c8d7770c93d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+\n",
      "|add_one(v1)|\n",
      "+-----------+\n",
      "|          2|\n",
      "|          3|\n",
      "|          4|\n",
      "|          5|\n",
      "|          6|\n",
      "|          7|\n",
      "|          8|\n",
      "|          9|\n",
      "+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# UDFs can be registered and invoked in SQL out of the box\n",
    "@pandas_udf(\"integer\")\n",
    "def add_one(s: pd.Series) -> pd.Series:\n",
    "    return s + 1\n",
    "\n",
    "spark.udf.register(\"add_one\", add_one)\n",
    "spark.sql(\"SELECT add_one(v1) FROM tableA\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "b66a862e-caa7-4583-acca-1e050e090bb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+\n",
      "|add_one(v1)|\n",
      "+-----------+\n",
      "|          2|\n",
      "|          3|\n",
      "|          4|\n",
      "|          5|\n",
      "|          6|\n",
      "|          7|\n",
      "|          8|\n",
      "|          9|\n",
      "+-----------+\n",
      "\n",
      "+--------------+\n",
      "|(count(1) > 0)|\n",
      "+--------------+\n",
      "|          true|\n",
      "+--------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# These SQL expressions can directly be mixed and used as PySpark columns.\n",
    "df.selectExpr('add_one(v1)').show()\n",
    "df.select(expr('count(*)') > 0).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae76bb87-7294-4e89-80ef-c6367bd5d294",
   "metadata": {},
   "source": [
    "## Close session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "7f3d15ed-f41b-4de2-b539-904ca7c090bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81412e53-744e-4878-afc6-3d7466be0e58",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
